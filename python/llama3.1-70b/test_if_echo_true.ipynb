{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-fc0c882825be424eba17658e8299dc7f',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1722920517,\n",
       " 'model': 'meta-llama/llama-3.1-405b-instruct',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"I'm so glad you're here. Is there something I can help you with? Do you have a question, need assistance with a task, or just want to chat? I'm all ears and here to help in any way I can.\"},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 26, 'completion_tokens': 49, 'total_tokens': 75},\n",
       " 'system_fingerprint': ''}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://api.novita.ai/v3/openai\"\n",
    "key = os.environ[\"NOVITA_API_KEY\"]\n",
    "headers = {\"Authorization\": f\"Bearer {key}\"}\n",
    "data = {\n",
    "    'model': 'meta-llama/llama-3.1-405b-instruct', \n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'Act like you are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Hi there!'\n",
    "        }\n",
    "    ],\n",
    "    'logprobs': True,\n",
    "    'top_logprobs': 1,\n",
    "    'echo': True\n",
    "}\n",
    "requests.post(f\"{base_url}/chat/completions\", headers=headers, json=data).json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f0d31485-3c35-46c0-ac33-5006e8b77ffb',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1722920546,\n",
       " 'model': 'accounts/fireworks/models/llama-v3p1-405b-instruct',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"<|start_header_id|>system<|end_header_id|>\\n\\nAct like you are a helpful assistant.<|start_header_id|>user<|end_header_id|>\\n\\nHi there!<|start_header_id|>assistant<|end_header_id|>\\n\\nHello! How can I assist you today? Do you have a question, need help with a task, or just want to chat? I'm here to help!\"},\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': {'content': [{'token': '',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       98,\n",
       "       101,\n",
       "       103,\n",
       "       105,\n",
       "       110,\n",
       "       95,\n",
       "       111,\n",
       "       102,\n",
       "       95,\n",
       "       116,\n",
       "       101,\n",
       "       120,\n",
       "       116,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': '!',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 0,\n",
       "        'bytes': [33]}],\n",
       "      'token_id': 128000,\n",
       "      'text_offset': 0},\n",
       "     {'token': '<|start_header_id|>',\n",
       "      'logprob': -0.00932312,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       115,\n",
       "       116,\n",
       "       97,\n",
       "       114,\n",
       "       116,\n",
       "       95,\n",
       "       104,\n",
       "       101,\n",
       "       97,\n",
       "       100,\n",
       "       101,\n",
       "       114,\n",
       "       95,\n",
       "       105,\n",
       "       100,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': '<|start_header_id|>',\n",
       "        'logprob': -0.00932312,\n",
       "        'token_id': 128006,\n",
       "        'bytes': [60,\n",
       "         124,\n",
       "         115,\n",
       "         116,\n",
       "         97,\n",
       "         114,\n",
       "         116,\n",
       "         95,\n",
       "         104,\n",
       "         101,\n",
       "         97,\n",
       "         100,\n",
       "         101,\n",
       "         114,\n",
       "         95,\n",
       "         105,\n",
       "         100,\n",
       "         124,\n",
       "         62]}],\n",
       "      'token_id': 128006,\n",
       "      'text_offset': 0},\n",
       "     {'token': 'system',\n",
       "      'logprob': -2.34179688,\n",
       "      'bytes': [115, 121, 115, 116, 101, 109],\n",
       "      'top_logprobs': [{'token': 'user',\n",
       "        'logprob': -2.34179688,\n",
       "        'token_id': 882,\n",
       "        'bytes': [117, 115, 101, 114]}],\n",
       "      'token_id': 9125,\n",
       "      'text_offset': 19},\n",
       "     {'token': '<|end_header_id|>',\n",
       "      'logprob': -10.03125,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       101,\n",
       "       110,\n",
       "       100,\n",
       "       95,\n",
       "       104,\n",
       "       101,\n",
       "       97,\n",
       "       100,\n",
       "       101,\n",
       "       114,\n",
       "       95,\n",
       "       105,\n",
       "       100,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': 'd',\n",
       "        'logprob': -2.29882812,\n",
       "        'token_id': 67,\n",
       "        'bytes': [100]}],\n",
       "      'token_id': 128007,\n",
       "      'text_offset': 25},\n",
       "     {'token': '\\n\\n',\n",
       "      'logprob': -0.55322266,\n",
       "      'bytes': [10, 10],\n",
       "      'top_logprobs': [{'token': '\\n\\n',\n",
       "        'logprob': -0.55322266,\n",
       "        'token_id': 271,\n",
       "        'bytes': [10, 10]}],\n",
       "      'token_id': 271,\n",
       "      'text_offset': 42},\n",
       "     {'token': 'Act',\n",
       "      'logprob': -3.60351562,\n",
       "      'bytes': [65, 99, 116],\n",
       "      'top_logprobs': [{'token': 'The',\n",
       "        'logprob': -2.15039062,\n",
       "        'token_id': 791,\n",
       "        'bytes': [84, 104, 101]}],\n",
       "      'token_id': 2471,\n",
       "      'text_offset': 44},\n",
       "     {'token': ' like',\n",
       "      'logprob': -4.4921875,\n",
       "      'bytes': [32, 108, 105, 107, 101],\n",
       "      'top_logprobs': [{'token': 'ing',\n",
       "        'logprob': -1.09472656,\n",
       "        'token_id': 287,\n",
       "        'bytes': [105, 110, 103]}],\n",
       "      'token_id': 1093,\n",
       "      'text_offset': 47},\n",
       "     {'token': ' you',\n",
       "      'logprob': -1.0234375,\n",
       "      'bytes': [32, 121, 111, 117],\n",
       "      'top_logprobs': [{'token': ' a',\n",
       "        'logprob': -0.7890625,\n",
       "        'token_id': 264,\n",
       "        'bytes': [32, 97]}],\n",
       "      'token_id': 499,\n",
       "      'text_offset': 52},\n",
       "     {'token': ' are',\n",
       "      'logprob': -0.60644531,\n",
       "      'bytes': [32, 97, 114, 101],\n",
       "      'top_logprobs': [{'token': ' are',\n",
       "        'logprob': -0.60644531,\n",
       "        'token_id': 527,\n",
       "        'bytes': [32, 97, 114, 101]}],\n",
       "      'token_id': 527,\n",
       "      'text_offset': 56},\n",
       "     {'token': ' a',\n",
       "      'logprob': -0.98779297,\n",
       "      'bytes': [32, 97],\n",
       "      'top_logprobs': [{'token': ' a',\n",
       "        'logprob': -0.98779297,\n",
       "        'token_id': 264,\n",
       "        'bytes': [32, 97]}],\n",
       "      'token_id': 264,\n",
       "      'text_offset': 60},\n",
       "     {'token': ' helpful',\n",
       "      'logprob': -7.52734375,\n",
       "      'bytes': [32, 104, 101, 108, 112, 102, 117, 108],\n",
       "      'top_logprobs': [{'token': ' detective',\n",
       "        'logprob': -3.58007812,\n",
       "        'token_id': 45259,\n",
       "        'bytes': [32, 100, 101, 116, 101, 99, 116, 105, 118, 101]}],\n",
       "      'token_id': 11190,\n",
       "      'text_offset': 62},\n",
       "     {'token': ' assistant',\n",
       "      'logprob': -1.32324219,\n",
       "      'bytes': [32, 97, 115, 115, 105, 115, 116, 97, 110, 116],\n",
       "      'top_logprobs': [{'token': ' assistant',\n",
       "        'logprob': -1.32324219,\n",
       "        'token_id': 18328,\n",
       "        'bytes': [32, 97, 115, 115, 105, 115, 116, 97, 110, 116]}],\n",
       "      'token_id': 18328,\n",
       "      'text_offset': 70},\n",
       "     {'token': '.',\n",
       "      'logprob': -1.6328125,\n",
       "      'bytes': [46],\n",
       "      'top_logprobs': [{'token': '.',\n",
       "        'logprob': -1.6328125,\n",
       "        'token_id': 13,\n",
       "        'bytes': [46]}],\n",
       "      'token_id': 13,\n",
       "      'text_offset': 80},\n",
       "     {'token': '',\n",
       "      'logprob': -5.015625,\n",
       "      'bytes': [60, 124, 101, 111, 116, 95, 105, 100, 124, 62],\n",
       "      'top_logprobs': [{'token': ' Can',\n",
       "        'logprob': -1.31347656,\n",
       "        'token_id': 3053,\n",
       "        'bytes': [32, 67, 97, 110]}],\n",
       "      'token_id': 128009,\n",
       "      'text_offset': 81},\n",
       "     {'token': '<|start_header_id|>',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       115,\n",
       "       116,\n",
       "       97,\n",
       "       114,\n",
       "       116,\n",
       "       95,\n",
       "       104,\n",
       "       101,\n",
       "       97,\n",
       "       100,\n",
       "       101,\n",
       "       114,\n",
       "       95,\n",
       "       105,\n",
       "       100,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': '<|start_header_id|>',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 128006,\n",
       "        'bytes': [60,\n",
       "         124,\n",
       "         115,\n",
       "         116,\n",
       "         97,\n",
       "         114,\n",
       "         116,\n",
       "         95,\n",
       "         104,\n",
       "         101,\n",
       "         97,\n",
       "         100,\n",
       "         101,\n",
       "         114,\n",
       "         95,\n",
       "         105,\n",
       "         100,\n",
       "         124,\n",
       "         62]}],\n",
       "      'token_id': 128006,\n",
       "      'text_offset': 81},\n",
       "     {'token': 'user',\n",
       "      'logprob': -15.9453125,\n",
       "      'bytes': [117, 115, 101, 114],\n",
       "      'top_logprobs': [{'token': 'assistant',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 78191,\n",
       "        'bytes': [97, 115, 115, 105, 115, 116, 97, 110, 116]}],\n",
       "      'token_id': 882,\n",
       "      'text_offset': 100},\n",
       "     {'token': '<|end_header_id|>',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       101,\n",
       "       110,\n",
       "       100,\n",
       "       95,\n",
       "       104,\n",
       "       101,\n",
       "       97,\n",
       "       100,\n",
       "       101,\n",
       "       114,\n",
       "       95,\n",
       "       105,\n",
       "       100,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': '<|end_header_id|>',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 128007,\n",
       "        'bytes': [60,\n",
       "         124,\n",
       "         101,\n",
       "         110,\n",
       "         100,\n",
       "         95,\n",
       "         104,\n",
       "         101,\n",
       "         97,\n",
       "         100,\n",
       "         101,\n",
       "         114,\n",
       "         95,\n",
       "         105,\n",
       "         100,\n",
       "         124,\n",
       "         62]}],\n",
       "      'token_id': 128007,\n",
       "      'text_offset': 104},\n",
       "     {'token': '\\n\\n',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [10, 10],\n",
       "      'top_logprobs': [{'token': '\\n\\n',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 271,\n",
       "        'bytes': [10, 10]}],\n",
       "      'token_id': 271,\n",
       "      'text_offset': 121},\n",
       "     {'token': 'Hi',\n",
       "      'logprob': -5.96484375,\n",
       "      'bytes': [72, 105],\n",
       "      'top_logprobs': [{'token': 'I',\n",
       "        'logprob': -0.49609375,\n",
       "        'token_id': 40,\n",
       "        'bytes': [73]}],\n",
       "      'token_id': 13347,\n",
       "      'text_offset': 123},\n",
       "     {'token': ' there',\n",
       "      'logprob': -1.50195312,\n",
       "      'bytes': [32, 116, 104, 101, 114, 101],\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': -0.62695312,\n",
       "        'token_id': 11,\n",
       "        'bytes': [44]}],\n",
       "      'token_id': 1070,\n",
       "      'text_offset': 125},\n",
       "     {'token': '!',\n",
       "      'logprob': -1.08105469,\n",
       "      'bytes': [33],\n",
       "      'top_logprobs': [{'token': '!',\n",
       "        'logprob': -1.08105469,\n",
       "        'token_id': 0,\n",
       "        'bytes': [33]}],\n",
       "      'token_id': 0,\n",
       "      'text_offset': 131},\n",
       "     {'token': '',\n",
       "      'logprob': -7.484375,\n",
       "      'bytes': [60, 124, 101, 111, 116, 95, 105, 100, 124, 62],\n",
       "      'top_logprobs': [{'token': ' I',\n",
       "        'logprob': -0.3515625,\n",
       "        'token_id': 358,\n",
       "        'bytes': [32, 73]}],\n",
       "      'token_id': 128009,\n",
       "      'text_offset': 132},\n",
       "     {'token': '<|start_header_id|>',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       115,\n",
       "       116,\n",
       "       97,\n",
       "       114,\n",
       "       116,\n",
       "       95,\n",
       "       104,\n",
       "       101,\n",
       "       97,\n",
       "       100,\n",
       "       101,\n",
       "       114,\n",
       "       95,\n",
       "       105,\n",
       "       100,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': '<|start_header_id|>',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 128006,\n",
       "        'bytes': [60,\n",
       "         124,\n",
       "         115,\n",
       "         116,\n",
       "         97,\n",
       "         114,\n",
       "         116,\n",
       "         95,\n",
       "         104,\n",
       "         101,\n",
       "         97,\n",
       "         100,\n",
       "         101,\n",
       "         114,\n",
       "         95,\n",
       "         105,\n",
       "         100,\n",
       "         124,\n",
       "         62]}],\n",
       "      'token_id': 128006,\n",
       "      'text_offset': 132},\n",
       "     {'token': 'assistant',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [97, 115, 115, 105, 115, 116, 97, 110, 116],\n",
       "      'top_logprobs': [{'token': 'assistant',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 78191,\n",
       "        'bytes': [97, 115, 115, 105, 115, 116, 97, 110, 116]}],\n",
       "      'token_id': 78191,\n",
       "      'text_offset': 151},\n",
       "     {'token': '<|end_header_id|>',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [60,\n",
       "       124,\n",
       "       101,\n",
       "       110,\n",
       "       100,\n",
       "       95,\n",
       "       104,\n",
       "       101,\n",
       "       97,\n",
       "       100,\n",
       "       101,\n",
       "       114,\n",
       "       95,\n",
       "       105,\n",
       "       100,\n",
       "       124,\n",
       "       62],\n",
       "      'top_logprobs': [{'token': '<|end_header_id|>',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 128007,\n",
       "        'bytes': [60,\n",
       "         124,\n",
       "         101,\n",
       "         110,\n",
       "         100,\n",
       "         95,\n",
       "         104,\n",
       "         101,\n",
       "         97,\n",
       "         100,\n",
       "         101,\n",
       "         114,\n",
       "         95,\n",
       "         105,\n",
       "         100,\n",
       "         124,\n",
       "         62]}],\n",
       "      'token_id': 128007,\n",
       "      'text_offset': 160},\n",
       "     {'token': '\\n\\n',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [10, 10],\n",
       "      'top_logprobs': [{'token': '\\n\\n',\n",
       "        'logprob': 0.0,\n",
       "        'token_id': 271,\n",
       "        'bytes': [10, 10]}],\n",
       "      'token_id': 271,\n",
       "      'text_offset': 177},\n",
       "     {'token': 'Hello',\n",
       "      'logprob': -0.19366932,\n",
       "      'bytes': [72, 101, 108, 108, 111],\n",
       "      'top_logprobs': [{'token': 'Hello',\n",
       "        'logprob': -0.19366932,\n",
       "        'token_id': 9906,\n",
       "        'bytes': [72, 101, 108, 108, 111]}],\n",
       "      'token_id': 9906,\n",
       "      'text_offset': 179},\n",
       "     {'token': '!',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [33],\n",
       "      'top_logprobs': [{'token': '!',\n",
       "        'logprob': -0.00147744,\n",
       "        'token_id': 0,\n",
       "        'bytes': [33]}],\n",
       "      'token_id': 0,\n",
       "      'text_offset': 184},\n",
       "     {'token': ' How',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 72, 111, 119],\n",
       "      'top_logprobs': [{'token': ' It',\n",
       "        'logprob': -0.57740718,\n",
       "        'token_id': 1102,\n",
       "        'bytes': [32, 73, 116]}],\n",
       "      'token_id': 2650,\n",
       "      'text_offset': 185},\n",
       "     {'token': ' can',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 99, 97, 110],\n",
       "      'top_logprobs': [{'token': ' can',\n",
       "        'logprob': -0.00410738,\n",
       "        'token_id': 649,\n",
       "        'bytes': [32, 99, 97, 110]}],\n",
       "      'token_id': 649,\n",
       "      'text_offset': 189},\n",
       "     {'token': ' I',\n",
       "      'logprob': -1.2e-07,\n",
       "      'bytes': [32, 73],\n",
       "      'top_logprobs': [{'token': ' I',\n",
       "        'logprob': -1.2e-07,\n",
       "        'token_id': 358,\n",
       "        'bytes': [32, 73]}],\n",
       "      'token_id': 358,\n",
       "      'text_offset': 193},\n",
       "     {'token': ' assist',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 97, 115, 115, 105, 115, 116],\n",
       "      'top_logprobs': [{'token': ' assist',\n",
       "        'logprob': -0.09735256,\n",
       "        'token_id': 7945,\n",
       "        'bytes': [32, 97, 115, 115, 105, 115, 116]}],\n",
       "      'token_id': 7945,\n",
       "      'text_offset': 195},\n",
       "     {'token': ' you',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 121, 111, 117],\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': 1.2e-07,\n",
       "        'token_id': 499,\n",
       "        'bytes': [32, 121, 111, 117]}],\n",
       "      'token_id': 499,\n",
       "      'text_offset': 202},\n",
       "     {'token': ' today',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 116, 111, 100, 97, 121],\n",
       "      'top_logprobs': [{'token': ' today',\n",
       "        'logprob': -2.38e-06,\n",
       "        'token_id': 3432,\n",
       "        'bytes': [32, 116, 111, 100, 97, 121]}],\n",
       "      'token_id': 3432,\n",
       "      'text_offset': 206},\n",
       "     {'token': '?',\n",
       "      'logprob': -9.5e-07,\n",
       "      'bytes': [63],\n",
       "      'top_logprobs': [{'token': '?',\n",
       "        'logprob': -9.5e-07,\n",
       "        'token_id': 30,\n",
       "        'bytes': [63]}],\n",
       "      'token_id': 30,\n",
       "      'text_offset': 212},\n",
       "     {'token': ' Do',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 68, 111],\n",
       "      'top_logprobs': [{'token': ' Do',\n",
       "        'logprob': -0.01337178,\n",
       "        'token_id': 3234,\n",
       "        'bytes': [32, 68, 111]}],\n",
       "      'token_id': 3234,\n",
       "      'text_offset': 213},\n",
       "     {'token': ' you',\n",
       "      'logprob': -2.4e-07,\n",
       "      'bytes': [32, 121, 111, 117],\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': -2.4e-07,\n",
       "        'token_id': 499,\n",
       "        'bytes': [32, 121, 111, 117]}],\n",
       "      'token_id': 499,\n",
       "      'text_offset': 216},\n",
       "     {'token': ' have',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 104, 97, 118, 101],\n",
       "      'top_logprobs': [{'token': ' have',\n",
       "        'logprob': -0.21918544,\n",
       "        'token_id': 617,\n",
       "        'bytes': [32, 104, 97, 118, 101]}],\n",
       "      'token_id': 617,\n",
       "      'text_offset': 220},\n",
       "     {'token': ' a',\n",
       "      'logprob': -0.53632993,\n",
       "      'bytes': [32, 97],\n",
       "      'top_logprobs': [{'token': ' a',\n",
       "        'logprob': -0.53632993,\n",
       "        'token_id': 264,\n",
       "        'bytes': [32, 97]}],\n",
       "      'token_id': 264,\n",
       "      'text_offset': 225},\n",
       "     {'token': ' question',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 113, 117, 101, 115, 116, 105, 111, 110],\n",
       "      'top_logprobs': [{'token': ' question',\n",
       "        'logprob': -0.26121983,\n",
       "        'token_id': 3488,\n",
       "        'bytes': [32, 113, 117, 101, 115, 116, 105, 111, 110]}],\n",
       "      'token_id': 3488,\n",
       "      'text_offset': 227},\n",
       "     {'token': ',',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [44],\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': -5.055e-05,\n",
       "        'token_id': 11,\n",
       "        'bytes': [44]}],\n",
       "      'token_id': 11,\n",
       "      'text_offset': 236},\n",
       "     {'token': ' need',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 110, 101, 101, 100],\n",
       "      'top_logprobs': [{'token': ' need',\n",
       "        'logprob': -0.11296467,\n",
       "        'token_id': 1205,\n",
       "        'bytes': [32, 110, 101, 101, 100]}],\n",
       "      'token_id': 1205,\n",
       "      'text_offset': 237},\n",
       "     {'token': ' help',\n",
       "      'logprob': -0.00019809,\n",
       "      'bytes': [32, 104, 101, 108, 112],\n",
       "      'top_logprobs': [{'token': ' help',\n",
       "        'logprob': -0.00019809,\n",
       "        'token_id': 1520,\n",
       "        'bytes': [32, 104, 101, 108, 112]}],\n",
       "      'token_id': 1520,\n",
       "      'text_offset': 242},\n",
       "     {'token': ' with',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'top_logprobs': [{'token': ' with',\n",
       "        'logprob': 1.2e-07,\n",
       "        'token_id': 449,\n",
       "        'bytes': [32, 119, 105, 116, 104]}],\n",
       "      'token_id': 449,\n",
       "      'text_offset': 247},\n",
       "     {'token': ' a',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 97],\n",
       "      'top_logprobs': [{'token': ' a',\n",
       "        'logprob': -0.00557022,\n",
       "        'token_id': 264,\n",
       "        'bytes': [32, 97]}],\n",
       "      'token_id': 264,\n",
       "      'text_offset': 252},\n",
       "     {'token': ' task',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 116, 97, 115, 107],\n",
       "      'top_logprobs': [{'token': ' task',\n",
       "        'logprob': -0.01715885,\n",
       "        'token_id': 3465,\n",
       "        'bytes': [32, 116, 97, 115, 107]}],\n",
       "      'token_id': 3465,\n",
       "      'text_offset': 254},\n",
       "     {'token': ',',\n",
       "      'logprob': -1.2e-07,\n",
       "      'bytes': [44],\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': -1.2e-07,\n",
       "        'token_id': 11,\n",
       "        'bytes': [44]}],\n",
       "      'token_id': 11,\n",
       "      'text_offset': 259},\n",
       "     {'token': ' or',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 111, 114],\n",
       "      'top_logprobs': [{'token': ' or',\n",
       "        'logprob': 1.2e-07,\n",
       "        'token_id': 477,\n",
       "        'bytes': [32, 111, 114]}],\n",
       "      'token_id': 477,\n",
       "      'text_offset': 260},\n",
       "     {'token': ' just',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 106, 117, 115, 116],\n",
       "      'top_logprobs': [{'token': ' just',\n",
       "        'logprob': -0.04555694,\n",
       "        'token_id': 1120,\n",
       "        'bytes': [32, 106, 117, 115, 116]}],\n",
       "      'token_id': 1120,\n",
       "      'text_offset': 263},\n",
       "     {'token': ' want',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 119, 97, 110, 116],\n",
       "      'top_logprobs': [{'token': ' want',\n",
       "        'logprob': -0.1505716,\n",
       "        'token_id': 1390,\n",
       "        'bytes': [32, 119, 97, 110, 116]}],\n",
       "      'token_id': 1390,\n",
       "      'text_offset': 268},\n",
       "     {'token': ' to',\n",
       "      'logprob': -0.75118852,\n",
       "      'bytes': [32, 116, 111],\n",
       "      'top_logprobs': [{'token': ' some',\n",
       "        'logprob': -0.73556352,\n",
       "        'token_id': 1063,\n",
       "        'bytes': [32, 115, 111, 109, 101]}],\n",
       "      'token_id': 311,\n",
       "      'text_offset': 273},\n",
       "     {'token': ' chat',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 99, 104, 97, 116],\n",
       "      'top_logprobs': [{'token': ' chat',\n",
       "        'logprob': -0.00054488,\n",
       "        'token_id': 6369,\n",
       "        'bytes': [32, 99, 104, 97, 116]}],\n",
       "      'token_id': 6369,\n",
       "      'text_offset': 276},\n",
       "     {'token': '?',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [63],\n",
       "      'top_logprobs': [{'token': '?',\n",
       "        'logprob': -0.00195933,\n",
       "        'token_id': 30,\n",
       "        'bytes': [63]}],\n",
       "      'token_id': 30,\n",
       "      'text_offset': 281},\n",
       "     {'token': ' I',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 73],\n",
       "      'top_logprobs': [{'token': ' I',\n",
       "        'logprob': -0.03926482,\n",
       "        'token_id': 358,\n",
       "        'bytes': [32, 73]}],\n",
       "      'token_id': 358,\n",
       "      'text_offset': 282},\n",
       "     {'token': \"'m\",\n",
       "      'logprob': 1.2e-07,\n",
       "      'bytes': [39, 109],\n",
       "      'top_logprobs': [{'token': \"'m\",\n",
       "        'logprob': 1.2e-07,\n",
       "        'token_id': 2846,\n",
       "        'bytes': [39, 109]}],\n",
       "      'token_id': 2846,\n",
       "      'text_offset': 284},\n",
       "     {'token': ' here',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 104, 101, 114, 101],\n",
       "      'top_logprobs': [{'token': ' here',\n",
       "        'logprob': -0.30495295,\n",
       "        'token_id': 1618,\n",
       "        'bytes': [32, 104, 101, 114, 101]}],\n",
       "      'token_id': 1618,\n",
       "      'text_offset': 286},\n",
       "     {'token': ' to',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 116, 111],\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': -2.15e-06,\n",
       "        'token_id': 311,\n",
       "        'bytes': [32, 116, 111]}],\n",
       "      'token_id': 311,\n",
       "      'text_offset': 291},\n",
       "     {'token': ' help',\n",
       "      'logprob': -16.1180954,\n",
       "      'bytes': [32, 104, 101, 108, 112],\n",
       "      'top_logprobs': [{'token': ' help',\n",
       "        'logprob': -0.05906855,\n",
       "        'token_id': 1520,\n",
       "        'bytes': [32, 104, 101, 108, 112]}],\n",
       "      'token_id': 1520,\n",
       "      'text_offset': 294},\n",
       "     {'token': '!',\n",
       "      'logprob': -1.01327014,\n",
       "      'bytes': [33],\n",
       "      'top_logprobs': [{'token': ' in',\n",
       "        'logprob': -0.88827014,\n",
       "        'token_id': 304,\n",
       "        'bytes': [32, 105, 110]}],\n",
       "      'token_id': 0,\n",
       "      'text_offset': 299},\n",
       "     {'token': '',\n",
       "      'logprob': -0.00114136,\n",
       "      'bytes': [60, 124, 101, 111, 116, 95, 105, 100, 124, 62],\n",
       "      'top_logprobs': [{'token': '<|eot_id|>',\n",
       "        'logprob': -0.00114136,\n",
       "        'token_id': 128009,\n",
       "        'bytes': [60, 124, 101, 111, 116, 95, 105, 100, 124, 62]}],\n",
       "      'token_id': 128009,\n",
       "      'text_offset': 300}]}}],\n",
       " 'usage': {'prompt_tokens': 26, 'total_tokens': 60, 'completion_tokens': 34}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://api.fireworks.ai/inference/v1\"\n",
    "key = os.environ[\"FIREWORKS_API_KEY\"]\n",
    "headers = {\"Authorization\": f\"Bearer {key}\"}\n",
    "data = {\n",
    "    'model': 'accounts/fireworks/models/llama-v3p1-405b-instruct', \n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'Act like you are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Hi there!'\n",
    "        }\n",
    "    ],\n",
    "    'logprobs': True,\n",
    "    'top_logprobs': 1,\n",
    "    'echo': True\n",
    "}\n",
    "requests.post(f\"{base_url}/chat/completions\", headers=headers, json=data).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-ef6495cba4784b95a5a45aedd90cfb53',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1722921025,\n",
       " 'model': 'meta-llama-3.1-405b-instruct',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"Hello! It's nice to meet you. Is there something I can help you with today? Whether you have a question, need assistance with a task, or just want to chat, I'm here to assist you. How can I help?\"},\n",
       "   'logprobs': {'content': [{'token': 'Hello',\n",
       "      'logprob': 1.109868049621582,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': 'Hello',\n",
       "        'logprob': 1.109868049621582,\n",
       "        'bytes': None}]},\n",
       "     {'token': '!',\n",
       "      'logprob': -1.318325161933899,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': '!',\n",
       "        'logprob': -1.318325161933899,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' It',\n",
       "      'logprob': -0.8748188614845276,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' It',\n",
       "        'logprob': -0.8748188614845276,\n",
       "        'bytes': None}]},\n",
       "     {'token': \"'s\",\n",
       "      'logprob': 0.35896503925323486,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': \"'s\",\n",
       "        'logprob': 0.35896503925323486,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' nice',\n",
       "      'logprob': -0.79808509349823,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' nice',\n",
       "        'logprob': -0.79808509349823,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' to',\n",
       "      'logprob': -0.8459963202476501,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': -0.8459963202476501,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' meet',\n",
       "      'logprob': 2.525355577468872,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' meet',\n",
       "        'logprob': 2.525355577468872,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': 0.1954232156276703,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': 0.1954232156276703,\n",
       "        'bytes': None}]},\n",
       "     {'token': '.',\n",
       "      'logprob': 1.7703540325164795,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': '.',\n",
       "        'logprob': 1.7703540325164795,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' Is',\n",
       "      'logprob': 0.6552587747573853,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' Is',\n",
       "        'logprob': 0.6552587747573853,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' there',\n",
       "      'logprob': -1.3463432788848877,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' there',\n",
       "        'logprob': -1.3463432788848877,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' something',\n",
       "      'logprob': 0.2228526473045349,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' something',\n",
       "        'logprob': 0.2228526473045349,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' I',\n",
       "      'logprob': -0.12927989661693573,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' I',\n",
       "        'logprob': -0.12927989661693573,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' can',\n",
       "      'logprob': -0.5738282203674316,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' can',\n",
       "        'logprob': -0.5738282203674316,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' help',\n",
       "      'logprob': 2.0793275833129883,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' help',\n",
       "        'logprob': 2.0793275833129883,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': -0.09695824235677719,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': -0.09695824235677719,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' with',\n",
       "      'logprob': -1.3606905937194824,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' with',\n",
       "        'logprob': -1.3606905937194824,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' today',\n",
       "      'logprob': 0.29609414935112,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' today',\n",
       "        'logprob': 0.29609414935112,\n",
       "        'bytes': None}]},\n",
       "     {'token': '?',\n",
       "      'logprob': 0.2973223626613617,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': '?',\n",
       "        'logprob': 0.2973223626613617,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' Whether',\n",
       "      'logprob': 1.3053808212280273,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' Whether',\n",
       "        'logprob': 1.3053808212280273,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': 0.23311752080917358,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': 0.23311752080917358,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' have',\n",
       "      'logprob': -0.7187467813491821,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' have',\n",
       "        'logprob': -0.7187467813491821,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' a',\n",
       "      'logprob': 0.1545238345861435,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' a',\n",
       "        'logprob': 0.1545238345861435,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' question',\n",
       "      'logprob': 3.6383938789367676,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' question',\n",
       "        'logprob': 3.6383938789367676,\n",
       "        'bytes': None}]},\n",
       "     {'token': ',',\n",
       "      'logprob': 0.17383503913879395,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': 0.17383503913879395,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' need',\n",
       "      'logprob': -0.649939239025116,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' need',\n",
       "        'logprob': -0.649939239025116,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' assistance',\n",
       "      'logprob': 0.19744038581848145,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' assistance',\n",
       "        'logprob': 0.19744038581848145,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' with',\n",
       "      'logprob': 0.23851458728313446,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' with',\n",
       "        'logprob': 0.23851458728313446,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' a',\n",
       "      'logprob': -0.3749706745147705,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' a',\n",
       "        'logprob': -0.3749706745147705,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' task',\n",
       "      'logprob': 0.24027755856513977,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' task',\n",
       "        'logprob': 0.24027755856513977,\n",
       "        'bytes': None}]},\n",
       "     {'token': ',',\n",
       "      'logprob': 0.36627307534217834,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': 0.36627307534217834,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' or',\n",
       "      'logprob': -0.49160122871398926,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' or',\n",
       "        'logprob': -0.49160122871398926,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' just',\n",
       "      'logprob': -0.6773377656936646,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' just',\n",
       "        'logprob': -0.6773377656936646,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' want',\n",
       "      'logprob': 0.23855383694171906,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' want',\n",
       "        'logprob': 0.23855383694171906,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' to',\n",
       "      'logprob': 1.2266682386398315,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': 1.2266682386398315,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' chat',\n",
       "      'logprob': 1.6243973970413208,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' chat',\n",
       "        'logprob': 1.6243973970413208,\n",
       "        'bytes': None}]},\n",
       "     {'token': ',',\n",
       "      'logprob': -0.3997190594673157,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': -0.3997190594673157,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' I',\n",
       "      'logprob': 0.21471580862998962,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' I',\n",
       "        'logprob': 0.21471580862998962,\n",
       "        'bytes': None}]},\n",
       "     {'token': \"'m\",\n",
       "      'logprob': -0.2668406367301941,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': \"'m\",\n",
       "        'logprob': -0.2668406367301941,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' here',\n",
       "      'logprob': -1.4775099754333496,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' here',\n",
       "        'logprob': -1.4775099754333496,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' to',\n",
       "      'logprob': 3.6990926265716553,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': 3.6990926265716553,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' assist',\n",
       "      'logprob': 3.2455663681030273,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' assist',\n",
       "        'logprob': 3.2455663681030273,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': -0.051976483315229416,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': -0.051976483315229416,\n",
       "        'bytes': None}]},\n",
       "     {'token': '.',\n",
       "      'logprob': 1.35422945022583,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': '.',\n",
       "        'logprob': 1.35422945022583,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' How',\n",
       "      'logprob': -1.3249584436416626,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' How',\n",
       "        'logprob': -1.3249584436416626,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' can',\n",
       "      'logprob': 1.8342546224594116,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' can',\n",
       "        'logprob': 1.8342546224594116,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' I',\n",
       "      'logprob': 1.746909260749817,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' I',\n",
       "        'logprob': 1.746909260749817,\n",
       "        'bytes': None}]},\n",
       "     {'token': ' help',\n",
       "      'logprob': -0.11554762721061707,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': ' help',\n",
       "        'logprob': -0.11554762721061707,\n",
       "        'bytes': None}]},\n",
       "     {'token': '?',\n",
       "      'logprob': -0.7645704746246338,\n",
       "      'bytes': None,\n",
       "      'top_logprobs': [{'token': '?',\n",
       "        'logprob': -0.7645704746246338,\n",
       "        'bytes': None}]}]},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 46, 'completion_tokens': 49, 'total_tokens': 95}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://text.octoai.run/v1\"\n",
    "key = os.environ[\"OCTOAI_API_KEY\"]\n",
    "headers = {\"Authorization\": f\"Bearer {key}\"}\n",
    "data = {\n",
    "    'model': 'meta-llama-3.1-405b-instruct', \n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'Act like you are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Hi there!'\n",
    "        }\n",
    "    ],\n",
    "    'logprobs': True,\n",
    "    'top_logprobs': 1,\n",
    "    'echo': True\n",
    "}\n",
    "requests.post(f\"{base_url}/chat/completions\", headers=headers, json=data).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lepton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Q2fXSAh3LqpidQUqdHHkPy',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1722925914,\n",
       " 'model': 'llama3-1-405b',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"Hello! It's nice to meet you. Is there something I can help you with today? Whether you need assistance with a task, have a question, or just need some general guidance, I'm here to help. Please feel free to ask me anything!\",\n",
       "    'tool_calls': None},\n",
       "   'logprobs': {'content': [{'token': 'Hello',\n",
       "      'logprob': -0.056756336241960526,\n",
       "      'bytes': [72, 101, 108, 108, 111],\n",
       "      'top_logprobs': [{'token': 'Hello',\n",
       "        'logprob': -0.056756336241960526,\n",
       "        'bytes': [72, 101, 108, 108, 111]}]},\n",
       "     {'token': '!',\n",
       "      'logprob': -0.0009769945172592998,\n",
       "      'bytes': [33],\n",
       "      'top_logprobs': [{'token': '!',\n",
       "        'logprob': -0.0009769945172592998,\n",
       "        'bytes': [33]}]},\n",
       "     {'token': ' It',\n",
       "      'logprob': -0.5395545959472656,\n",
       "      'bytes': [32, 73, 116],\n",
       "      'top_logprobs': [{'token': ' It',\n",
       "        'logprob': -0.5395545959472656,\n",
       "        'bytes': [32, 73, 116]}]},\n",
       "     {'token': \"'s\",\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [39, 115],\n",
       "      'top_logprobs': [{'token': \"'s\", 'logprob': 0.0, 'bytes': [39, 115]}]},\n",
       "     {'token': ' nice',\n",
       "      'logprob': -0.8746877908706665,\n",
       "      'bytes': [32, 110, 105, 99, 101],\n",
       "      'top_logprobs': [{'token': ' great',\n",
       "        'logprob': -0.6567097306251526,\n",
       "        'bytes': [32, 103, 114, 101, 97, 116]}]},\n",
       "     {'token': ' to',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 116, 111],\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 116, 111]}]},\n",
       "     {'token': ' meet',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 109, 101, 101, 116],\n",
       "      'top_logprobs': [{'token': ' meet',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 109, 101, 101, 116]}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 121, 111, 117],\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 121, 111, 117]}]},\n",
       "     {'token': '.',\n",
       "      'logprob': -0.09039061516523361,\n",
       "      'bytes': [46],\n",
       "      'top_logprobs': [{'token': '.',\n",
       "        'logprob': -0.09039061516523361,\n",
       "        'bytes': [46]}]},\n",
       "     {'token': ' Is',\n",
       "      'logprob': -0.09039061516523361,\n",
       "      'bytes': [32, 73, 115],\n",
       "      'top_logprobs': [{'token': ' Is',\n",
       "        'logprob': -0.09039061516523361,\n",
       "        'bytes': [32, 73, 115]}]},\n",
       "     {'token': ' there',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 116, 104, 101, 114, 101],\n",
       "      'top_logprobs': [{'token': ' there',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 116, 104, 101, 114, 101]}]},\n",
       "     {'token': ' something',\n",
       "      'logprob': -0.1821262389421463,\n",
       "      'bytes': [32, 115, 111, 109, 101, 116, 104, 105, 110, 103],\n",
       "      'top_logprobs': [{'token': ' something',\n",
       "        'logprob': -0.1821262389421463,\n",
       "        'bytes': [32, 115, 111, 109, 101, 116, 104, 105, 110, 103]}]},\n",
       "     {'token': ' I',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 73],\n",
       "      'top_logprobs': [{'token': ' I', 'logprob': 0.0, 'bytes': [32, 73]}]},\n",
       "     {'token': ' can',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 99, 97, 110],\n",
       "      'top_logprobs': [{'token': ' can',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 99, 97, 110]}]},\n",
       "     {'token': ' help',\n",
       "      'logprob': -0.002933952258899808,\n",
       "      'bytes': [32, 104, 101, 108, 112],\n",
       "      'top_logprobs': [{'token': ' help',\n",
       "        'logprob': -0.002933952258899808,\n",
       "        'bytes': [32, 104, 101, 108, 112]}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 121, 111, 117],\n",
       "      'top_logprobs': [{'token': ' you',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 121, 111, 117]}]},\n",
       "     {'token': ' with',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'top_logprobs': [{'token': ' with',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 119, 105, 116, 104]}]},\n",
       "     {'token': ' today',\n",
       "      'logprob': -0.05160171538591385,\n",
       "      'bytes': [32, 116, 111, 100, 97, 121],\n",
       "      'top_logprobs': [{'token': ' today',\n",
       "        'logprob': -0.05160171538591385,\n",
       "        'bytes': [32, 116, 111, 100, 97, 121]}]},\n",
       "     {'token': '?',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [63],\n",
       "      'top_logprobs': [{'token': '?', 'logprob': 0.0, 'bytes': [63]}]},\n",
       "     {'token': ' Whether',\n",
       "      'logprob': -0.9627641439437866,\n",
       "      'bytes': [32, 87, 104, 101, 116, 104, 101, 114],\n",
       "      'top_logprobs': [{'token': ' Do',\n",
       "        'logprob': -0.541231095790863,\n",
       "        'bytes': [32, 68, 111]}]},\n",
       "     {'token': ' you',\n",
       "      'logprob': -0.870597779750824,\n",
       "      'bytes': [32, 121, 111, 117],\n",
       "      'top_logprobs': [{'token': ' it',\n",
       "        'logprob': -0.5420703887939453,\n",
       "        'bytes': [32, 105, 116]}]},\n",
       "     {'token': ' need',\n",
       "      'logprob': -0.22828365862369537,\n",
       "      'bytes': [32, 110, 101, 101, 100],\n",
       "      'top_logprobs': [{'token': ' need',\n",
       "        'logprob': -0.22828365862369537,\n",
       "        'bytes': [32, 110, 101, 101, 100]}]},\n",
       "     {'token': ' assistance',\n",
       "      'logprob': -0.00981358252465725,\n",
       "      'bytes': [32, 97, 115, 115, 105, 115, 116, 97, 110, 99, 101],\n",
       "      'top_logprobs': [{'token': ' assistance',\n",
       "        'logprob': -0.00981358252465725,\n",
       "        'bytes': [32, 97, 115, 115, 105, 115, 116, 97, 110, 99, 101]}]},\n",
       "     {'token': ' with',\n",
       "      'logprob': -0.002933952258899808,\n",
       "      'bytes': [32, 119, 105, 116, 104],\n",
       "      'top_logprobs': [{'token': ' with',\n",
       "        'logprob': -0.002933952258899808,\n",
       "        'bytes': [32, 119, 105, 116, 104]}]},\n",
       "     {'token': ' a',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 97],\n",
       "      'top_logprobs': [{'token': ' a', 'logprob': 0.0, 'bytes': [32, 97]}]},\n",
       "     {'token': ' task',\n",
       "      'logprob': -0.024216651916503906,\n",
       "      'bytes': [32, 116, 97, 115, 107],\n",
       "      'top_logprobs': [{'token': ' task',\n",
       "        'logprob': -0.024216651916503906,\n",
       "        'bytes': [32, 116, 97, 115, 107]}]},\n",
       "     {'token': ',',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [44],\n",
       "      'top_logprobs': [{'token': ',', 'logprob': 0.0, 'bytes': [44]}]},\n",
       "     {'token': ' have',\n",
       "      'logprob': -0.012282118201255798,\n",
       "      'bytes': [32, 104, 97, 118, 101],\n",
       "      'top_logprobs': [{'token': ' have',\n",
       "        'logprob': -0.012282118201255798,\n",
       "        'bytes': [32, 104, 97, 118, 101]}]},\n",
       "     {'token': ' a',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 97],\n",
       "      'top_logprobs': [{'token': ' a', 'logprob': 0.0, 'bytes': [32, 97]}]},\n",
       "     {'token': ' question',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 113, 117, 101, 115, 116, 105, 111, 110],\n",
       "      'top_logprobs': [{'token': ' question',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 113, 117, 101, 115, 116, 105, 111, 110]}]},\n",
       "     {'token': ',',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [44],\n",
       "      'top_logprobs': [{'token': ',', 'logprob': 0.0, 'bytes': [44]}]},\n",
       "     {'token': ' or',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 111, 114],\n",
       "      'top_logprobs': [{'token': ' or',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 111, 114]}]},\n",
       "     {'token': ' just',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 106, 117, 115, 116],\n",
       "      'top_logprobs': [{'token': ' just',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 106, 117, 115, 116]}]},\n",
       "     {'token': ' need',\n",
       "      'logprob': -0.38684073090553284,\n",
       "      'bytes': [32, 110, 101, 101, 100],\n",
       "      'top_logprobs': [{'token': ' need',\n",
       "        'logprob': -0.38684073090553284,\n",
       "        'bytes': [32, 110, 101, 101, 100]}]},\n",
       "     {'token': ' some',\n",
       "      'logprob': -1.0439798831939697,\n",
       "      'bytes': [32, 115, 111, 109, 101],\n",
       "      'top_logprobs': [{'token': ' someone',\n",
       "        'logprob': -0.4339429438114166,\n",
       "        'bytes': [32, 115, 111, 109, 101, 111, 110, 101]}]},\n",
       "     {'token': ' general',\n",
       "      'logprob': -1.3247509002685547,\n",
       "      'bytes': [32, 103, 101, 110, 101, 114, 97, 108],\n",
       "      'top_logprobs': [{'token': ' information',\n",
       "        'logprob': -0.7468075752258301,\n",
       "        'bytes': [32, 105, 110, 102, 111, 114, 109, 97, 116, 105, 111, 110]}]},\n",
       "     {'token': ' guidance',\n",
       "      'logprob': -0.14758042991161346,\n",
       "      'bytes': [32, 103, 117, 105, 100, 97, 110, 99, 101],\n",
       "      'top_logprobs': [{'token': ' guidance',\n",
       "        'logprob': -0.14758042991161346,\n",
       "        'bytes': [32, 103, 117, 105, 100, 97, 110, 99, 101]}]},\n",
       "     {'token': ',',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [44],\n",
       "      'top_logprobs': [{'token': ',', 'logprob': 0.0, 'bytes': [44]}]},\n",
       "     {'token': ' I',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 73],\n",
       "      'top_logprobs': [{'token': ' I', 'logprob': 0.0, 'bytes': [32, 73]}]},\n",
       "     {'token': \"'m\",\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [39, 109],\n",
       "      'top_logprobs': [{'token': \"'m\", 'logprob': 0.0, 'bytes': [39, 109]}]},\n",
       "     {'token': ' here',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 104, 101, 114, 101],\n",
       "      'top_logprobs': [{'token': ' here',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 104, 101, 114, 101]}]},\n",
       "     {'token': ' to',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 116, 111],\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 116, 111]}]},\n",
       "     {'token': ' help',\n",
       "      'logprob': -0.1285216212272644,\n",
       "      'bytes': [32, 104, 101, 108, 112],\n",
       "      'top_logprobs': [{'token': ' help',\n",
       "        'logprob': -0.1285216212272644,\n",
       "        'bytes': [32, 104, 101, 108, 112]}]},\n",
       "     {'token': '.',\n",
       "      'logprob': -0.006859394256025553,\n",
       "      'bytes': [46],\n",
       "      'top_logprobs': [{'token': '.',\n",
       "        'logprob': -0.006859394256025553,\n",
       "        'bytes': [46]}]},\n",
       "     {'token': ' Please',\n",
       "      'logprob': -1.6990270614624023,\n",
       "      'bytes': [32, 80, 108, 101, 97, 115, 101],\n",
       "      'top_logprobs': [{'token': ' What',\n",
       "        'logprob': -0.4331895709037781,\n",
       "        'bytes': [32, 87, 104, 97, 116]}]},\n",
       "     {'token': ' feel',\n",
       "      'logprob': -0.13241592049598694,\n",
       "      'bytes': [32, 102, 101, 101, 108],\n",
       "      'top_logprobs': [{'token': ' feel',\n",
       "        'logprob': -0.13241592049598694,\n",
       "        'bytes': [32, 102, 101, 101, 108]}]},\n",
       "     {'token': ' free',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 102, 114, 101, 101],\n",
       "      'top_logprobs': [{'token': ' free',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 102, 114, 101, 101]}]},\n",
       "     {'token': ' to',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 116, 111],\n",
       "      'top_logprobs': [{'token': ' to',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 116, 111]}]},\n",
       "     {'token': ' ask',\n",
       "      'logprob': -0.0495472326874733,\n",
       "      'bytes': [32, 97, 115, 107],\n",
       "      'top_logprobs': [{'token': ' ask',\n",
       "        'logprob': -0.0495472326874733,\n",
       "        'bytes': [32, 97, 115, 107]}]},\n",
       "     {'token': ' me',\n",
       "      'logprob': -0.01030680164694786,\n",
       "      'bytes': [32, 109, 101],\n",
       "      'top_logprobs': [{'token': ' me',\n",
       "        'logprob': -0.01030680164694786,\n",
       "        'bytes': [32, 109, 101]}]},\n",
       "     {'token': ' anything',\n",
       "      'logprob': 0.0,\n",
       "      'bytes': [32, 97, 110, 121, 116, 104, 105, 110, 103],\n",
       "      'top_logprobs': [{'token': ' anything',\n",
       "        'logprob': 0.0,\n",
       "        'bytes': [32, 97, 110, 121, 116, 104, 105, 110, 103]}]},\n",
       "     {'token': '!',\n",
       "      'logprob': -0.09467557072639465,\n",
       "      'bytes': [33],\n",
       "      'top_logprobs': [{'token': '!',\n",
       "        'logprob': -0.09467557072639465,\n",
       "        'bytes': [33]}]},\n",
       "     {'token': '<|eot_id|>',\n",
       "      'logprob': -0.001465873676352203,\n",
       "      'bytes': [60, 124, 101, 111, 116, 95, 105, 100, 124, 62],\n",
       "      'top_logprobs': [{'token': '<|eot_id|>',\n",
       "        'logprob': -0.001465873676352203,\n",
       "        'bytes': [60, 124, 101, 111, 116, 95, 105, 100, 124, 62]}]}]},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 26, 'total_tokens': 79, 'completion_tokens': 53}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://llama3-1-405b.lepton.run/api/v1\"\n",
    "key = os.environ[\"LEPTON_API_KEY\"]\n",
    "headers = {\"Authorization\": f\"Bearer {key}\"}\n",
    "data = {\n",
    "    'model': 'llama3-1-405b',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'Act like you are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Hi there!'\n",
    "        }\n",
    "    ],\n",
    "    'logprobs': True,\n",
    "    'top_logprobs': 1,\n",
    "    'echo': True\n",
    "}\n",
    "requests.post(f\"{base_url}/chat/completions\", headers=headers, json=data).json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
