{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pyquaternion as pyq\n",
    "import diff_gaussian_rasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts a set of gaussians that accurately represent an input image\n",
    "class GaussianPredictor(nn.Module):\n",
    "    def __init__(self, n_gaussians=7):\n",
    "        super().__init__()\n",
    "        self.n_gaussians = n_gaussians\n",
    "        # 64x64 -> 32x32\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        # 32x32 -> 16x16\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        # 16x16 -> 8x8\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 1024)\n",
    "        self.fc2 = nn.Linear(1024, n_gaussians*7) # [x, y, sx, sy, rx, ry, o] * n_gaussians\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B x 3 x 64 x 64\n",
    "        x = F.relu(self.conv1_bn(self.conv1(x)))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, self.n_gaussians, 7)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate orthographic projection matrix.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        torch.Tensor: orthographic projection matrix\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m     19\u001b[0m         [\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (right \u001b[38;5;241m-\u001b[39m left), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m(right \u001b[38;5;241m+\u001b[39m left) \u001b[38;5;241m/\u001b[39m (right \u001b[38;5;241m-\u001b[39m left)],\n\u001b[1;32m     20\u001b[0m         [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (top \u001b[38;5;241m-\u001b[39m bottom), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m(top \u001b[38;5;241m+\u001b[39m bottom) \u001b[38;5;241m/\u001b[39m (top \u001b[38;5;241m-\u001b[39m bottom)],\n\u001b[1;32m     21\u001b[0m         [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (far \u001b[38;5;241m-\u001b[39m near), \u001b[38;5;241m-\u001b[39m(far \u001b[38;5;241m+\u001b[39m near) \u001b[38;5;241m/\u001b[39m (far \u001b[38;5;241m-\u001b[39m near)],\n\u001b[1;32m     22\u001b[0m         [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     23\u001b[0m     ])\n\u001b[1;32m     25\u001b[0m raster_settings \u001b[38;5;241m=\u001b[39m diff_gaussian_rasterization\u001b[38;5;241m.\u001b[39mGaussianRasterizationSettings(\n\u001b[1;32m     26\u001b[0m     image_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     27\u001b[0m     image_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     28\u001b[0m     tanfovx\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mtan(FoVx \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     29\u001b[0m     tanfovy\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mtan(FoVy \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m---> 30\u001b[0m     bg\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     31\u001b[0m     scale_modifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     32\u001b[0m     viewmatrix\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m4\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice),\n\u001b[1;32m     33\u001b[0m     projmatrix\u001b[38;5;241m=\u001b[39mgen_orthographic_matrix(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     34\u001b[0m     sh_degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     35\u001b[0m     campos\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice),\n\u001b[1;32m     36\u001b[0m     prefiltered\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m rasterizer \u001b[38;5;241m=\u001b[39m diff_gaussian_rasterization\u001b[38;5;241m.\u001b[39mGaussianRasterizer(raster_settings\u001b[38;5;241m=\u001b[39mraster_settings)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender_images_batch\u001b[39m(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# [B, N, 2]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         means: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m         opacities: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m     51\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n",
      "File \u001b[0;32m~/venvs/infgen/lib/python3.11/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "FoVx = 90\n",
    "FoVy = 90\n",
    "\n",
    "def gen_orthographic_matrix(left: float, right: float, bottom: float, top: float, near: float, far: float):\n",
    "    \"\"\"Generate orthographic projection matrix.\n",
    "\n",
    "    Args:\n",
    "        left (float): left plane\n",
    "        right (float): right plane\n",
    "        bottom (float): bottom plane\n",
    "        top (float): top plane\n",
    "        near (float): near plane\n",
    "        far (float): far plane\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: orthographic projection matrix\n",
    "    \"\"\"\n",
    "    return torch.tensor([\n",
    "        [2 / (right - left), 0, 0, -(right + left) / (right - left)],\n",
    "        [0, 2 / (top - bottom), 0, -(top + bottom) / (top - bottom)],\n",
    "        [0, 0, -2 / (far - near), -(far + near) / (far - near)],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "raster_settings = diff_gaussian_rasterization.GaussianRasterizationSettings(\n",
    "    image_height=512,\n",
    "    image_width=512,\n",
    "    tanfovx=math.tan(FoVx * 0.5),\n",
    "    tanfovy=math.tan(FoVy * 0.5),\n",
    "    bg=torch.zeros(4, dtype=torch.float32, device=device),\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=torch.eye(4, dtype=torch.float32, device=device),\n",
    "    projmatrix=gen_orthographic_matrix(-1, 1, -1, 1, -1, 1).to(device),\n",
    "    sh_degree=1,\n",
    "    campos=torch.tensor([0, 0, 0], dtype=torch.float32, device=device),\n",
    "    prefiltered=False,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "rasterizer = diff_gaussian_rasterization.GaussianRasterizer(raster_settings=raster_settings)\n",
    "\n",
    "def render_images_batch(\n",
    "        # [B, N, 2]\n",
    "        means: torch.Tensor,\n",
    "        # [B, N, 2]\n",
    "        scales: torch.Tensor,\n",
    "        # [B, N, 2]\n",
    "        rotations: torch.Tensor,\n",
    "        # [B, N]\n",
    "        opacities: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    B, N = means.shape[:2]\n",
    "    assert N >= 0\n",
    "    assert means.shape == (B, N, 2)\n",
    "    assert opacities.shape == (B, N)\n",
    "    assert scales.shape == (B, N, 2)\n",
    "    assert rotations.shape == (B, N, 2)\n",
    "    assert opacities.shape == (B, N)\n",
    "\n",
    "    means3D = torch.cat([means, torch.zeros(B, 1, 2, dtype=torch.float32, device=device)], dim=1)\n",
    "    means2D = torch.zeros(B, N, 2, dtype=torch.float32, device=device)\n",
    "    rotations = torch.from_numpy(pyq.Quaternion().elements).to(device).unsqueeze(0).unsqueeze(0).expand(B, N, 4)\n",
    "    colors_precomp = torch.ones(B, N, 3, dtype=torch.float32, device=device)\n",
    "\n",
    "    imlist = []\n",
    "    for b in range(B):\n",
    "        rendered_image, _ = rasterizer(\n",
    "            means3D=means3D[b],\n",
    "            means2D=means2D[b],\n",
    "            colors_precomp=colors_precomp[b],\n",
    "            opacities=opacities[b],\n",
    "            scales=scales[b],\n",
    "            rotations=rotations[b],\n",
    "        )\n",
    "        imlist.append(rendered_image)\n",
    "    \n",
    "    return torch.stack(imlist, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_gaussian_predictor(\n",
    "    model: GaussianPredictor,\n",
    "    optim: torch.optim.Optimizer,\n",
    "    images: torch.Tensor,\n",
    ") -> float:\n",
    "    model.train()\n",
    "\n",
    "    images = images.to(device)\n",
    "\n",
    "    # predict gaussians\n",
    "    gaussian_preds = model(images)\n",
    "\n",
    "    # rasterize predictions\n",
    "    means_batched = gaussian_preds[:, :, :2]\n",
    "    scales_batched = gaussian_preds[:, :, 2:4]\n",
    "    rotations_batched = gaussian_preds[:, :, 4:6]\n",
    "    opacities_batched = gaussian_preds[:, :, 6]\n",
    "    rasterized_pred = render_images_batch(means_batched, scales_batched, rotations_batched, opacities_batched)\n",
    "\n",
    "    # compute loss\n",
    "    loss = F.mse_loss(rasterized_pred, images)\n",
    "\n",
    "    # step loss\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GaussianPredictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# create model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGaussianPredictor\u001b[49m()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GaussianPredictor' is not defined"
     ]
    }
   ],
   "source": [
    "# download mnist dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST('data', download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianPredictor().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# train model\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        loss = train_gaussian_predictor(model, optim, images)\n",
    "        print(f\"Loss: {loss}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
